{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b90248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (7000, 18)\n",
      "test  shape: (3000, 17)\n",
      "           ID  나이  키(cm)  몸무게(kg)    BMI    시력  충치  공복 혈당  혈압  중성 지방  \\\n",
      "0  TRAIN_0000  35    170       70  24.22  1.10   1     98  40     80   \n",
      "1  TRAIN_0001  40    150       55  24.44  1.00   0    173  39    104   \n",
      "2  TRAIN_0002  60    170       50  17.30  0.75   0     96  40     61   \n",
      "\n",
      "   혈청 크레아티닌  콜레스테롤  고밀도지단백  저밀도지단백  헤모글로빈  요 단백  간 효소율  label  \n",
      "0       1.3    211      75     120   15.9     1   1.53      1  \n",
      "1       0.6    251      46     184   11.8     1   1.45      0  \n",
      "2       0.8    144      43      89   15.3     1   1.04      0  \n",
      "\n",
      "사용 피처: ['나이', '키(cm)', '몸무게(kg)', 'BMI', '시력', '충치', '공복 혈당', '혈압', '중성 지방', '혈청 크레아티닌', '콜레스테롤', '고밀도지단백', '저밀도지단백', '헤모글로빈', '요 단백', '간 효소율']\n",
      "X shape: (7000, 16) / y shape: (7000,)\n",
      "\n",
      "X_train: (5600, 16) / X_valid: (1400, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 라이브러리 & 시드 고정\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "#  데이터 로드\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test  shape:\", test.shape)\n",
    "print(train.head(3))\n",
    "\n",
    "\n",
    "# Feature / Label 분리 (ID, label 제거)\n",
    "\n",
    "X = train.drop(columns=[\"ID\", \"label\"])\n",
    "y = train[\"label\"].values\n",
    "\n",
    "X_test_final = test.drop(columns=[\"ID\"])\n",
    "\n",
    "print(\"\\n사용 피처:\", X.columns.tolist())\n",
    "print(\"X shape:\", X.shape, \"/ y shape:\", y.shape)\n",
    "\n",
    "\n",
    "# Train / Valid 분리 (성능 확인용)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nX_train:\", X_train.shape, \"/ X_valid:\", X_valid.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46da7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train/Valid에서 학습 ===\n",
      "\n",
      "[최종 설정 Valid Accuracy] : 0.7586\n",
      "  (w_rf=0.75, w_xgb=0.25, thr=0.47)\n",
      "\n",
      "=== 전체 train 데이터(7000개)로 최종 학습 ===\n",
      "\n",
      " submission_kte_5.csv 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모델 \n",
    "# RandomForest (베스트 파라미터)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# XGBoost (베스트 파라미터)\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=700,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.07,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# \n",
    "# Train / Valid에서 성능 확인\n",
    "#\n",
    "print(\"\\n=== Train/Valid에서 학습 ===\")\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "rf_valid_proba  = rf.predict_proba(X_valid)[:, 1]\n",
    "xgb_valid_proba = xgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# Soft Voting (w_rf=0.75, w_xgb=0.25, thr=0.47)\n",
    "w_rf  = 0.75\n",
    "w_xgb = 0.25\n",
    "best_thr = 0.47\n",
    "\n",
    "ens_valid_proba = rf_valid_proba * w_rf + xgb_valid_proba * w_xgb\n",
    "ens_valid_pred  = (ens_valid_proba >= best_thr).astype(int)\n",
    "\n",
    "valid_acc = accuracy_score(y_valid, ens_valid_pred)\n",
    "print(f\"\\n[최종 설정 Valid Accuracy] : {valid_acc:.4f}\")\n",
    "print(f\"  (w_rf={w_rf}, w_xgb={w_xgb}, thr={best_thr})\")\n",
    "\n",
    "# \n",
    "# 전체 데이터로 다시 학습 후 Test 예측\n",
    "# \n",
    "print(\"\\n=== 전체 train 데이터(7000개)로 최종 학습 ===\")\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=1100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    n_estimators=700,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.07,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_final.fit(X, y)\n",
    "xgb_final.fit(X, y)\n",
    "\n",
    "rf_test_proba  = rf_final.predict_proba(X_test_final)[:, 1]\n",
    "xgb_test_proba = xgb_final.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "final_proba = rf_test_proba * w_rf + xgb_test_proba * w_xgb\n",
    "test_pred   = (final_proba >= best_thr).astype(int)\n",
    "\n",
    "\n",
    "# 제출 파일 생성\n",
    "\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission[\"label\"] = test_pred\n",
    "submission.to_csv(\"submission_kte_5.csv\", index=False)\n",
    "print(\"\\n submission_kte_5.csv 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53678226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842f6cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Train ACC : 0.9983928571428572\n",
      "XGB Train ACC: 0.9996428571428572\n"
     ]
    }
   ],
   "source": [
    "rf_train_pred = rf.predict(X_train)\n",
    "xgb_train_pred = xgb.predict(X_train)\n",
    "\n",
    "print(\"RF Train ACC :\", accuracy_score(y_train, rf_train_pred))\n",
    "print(\"XGB Train ACC:\", accuracy_score(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879ebe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
