{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f138f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23b3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be283405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이트 로드 /Feature / Label 분리\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X = train.drop([\"ID\", \"label\"], axis=1)\n",
    "y = train[\"label\"]\n",
    "X_test_final = test.drop(\"ID\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcabb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Valid 분리\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c6ad8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best threshold: 0.5700000000000003\n",
      " Valid Accuracy: 0.7557142857142857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RandomForest\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=7,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=4,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_valid_proba = rf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_valid_proba = xgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "\n",
    "# Soft Voting \n",
    "\n",
    "ensemble_proba = (rf_valid_proba * 0.6) + (xgb_valid_proba * 0.4)\n",
    "\n",
    "\n",
    "# Threshold\n",
    "\n",
    "best_acc = 0\n",
    "best_thr = 0.5\n",
    "\n",
    "for thr in np.arange(0.30, 0.71, 0.01):\n",
    "    pred = (ensemble_proba >= thr).astype(int)\n",
    "    acc = accuracy_score(y_valid, pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_thr = thr\n",
    "\n",
    "\n",
    "print(\" Best threshold:\", best_thr)\n",
    "print(\" Valid Accuracy:\", best_acc)\n",
    "\n",
    "\n",
    "\n",
    "# 최종 모델은 전체 Train \n",
    "\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=7,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=4,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_final.fit(X, y)\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "xgb_final.fit(X, y)\n",
    "\n",
    "# Soft Voting on Test\n",
    "rf_test = rf_final.predict_proba(X_test_final)[:, 1]\n",
    "xgb_test = xgb_final.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "test_ensemble = (rf_test * 0.6) + (xgb_test * 0.4)\n",
    "\n",
    "test_pred = (test_ensemble >= best_thr).astype(int)\n",
    "\n",
    "\n",
    "# Save submission\n",
    "\n",
    "# sub[\"label\"] = test_pred\n",
    "# sub.to_csv(\"submission_best.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67ea44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 과적합 체크 ===\n",
      "RF Train: 0.7473 / Valid: 0.7207\n",
      "XGB Train: 1.0000 / Valid: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# 과적합 체크\n",
    "rf_train_acc = accuracy_score(y_train, rf.predict(X_train))\n",
    "rf_valid_acc = accuracy_score(y_valid, rf.predict(X_valid))\n",
    "\n",
    "xgb_train_acc = accuracy_score(y_train, xgb.predict(X_train))\n",
    "xgb_valid_acc = accuracy_score(y_valid, xgb.predict(X_valid))\n",
    "\n",
    "print(\"=== 과적합 체크 ===\")\n",
    "print(f\"RF Train: {rf_train_acc:.4f} / Valid: {rf_valid_acc:.4f}\")\n",
    "print(f\"XGB Train: {xgb_train_acc:.4f} / Valid: {xgb_valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270238a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
