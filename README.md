# 1. 프로젝트 개요(Introduction)
## 1.1 문제 정의(Problem Definition)

* “건강 데이터에서 개인의 흡연 여부(label)를 예측하는 이진 분류(binary classification) 문제를 다룬다.”


* 입력: 건강검진 결과 및 특성(나이, BMI, 혈압, 혈액검사 등)

* 출력: 흡연 여부(흡연자 / 비흡연자,label)

* 목표: 데이터 분석결과 이상치나 결측치 보단 컬럼간의 상호관계및 우선도,
* 단순 정확도(accuracy) 흡연자를 놓치지 않는 재현율(recall) 을 우선시

## 지나친 과적합 없이, 데이터 분포 변화에도 견고한 모델 개발이 목적



# 1.2 비즈니스/의료적 관점에서의 중요성


흡연자는 향후 심혈관계·호흡기계 질환 위험이 높으므로, 조기 모니터링이 중요하다.

일반화: 의료 리스크 관점에서 “흡연자 → 양성 클래스(positive class)”로 두고,

위양성(검사시 양성 오탐)보다 위음성(검사시 음성 오탐) 을 더 크게 보는 의사결정 구조를 설명.

# 2. 데이터 및 전처리(Data & Preprocessing)
## 2.1 데이터 구성(Data Description)

(컬럼 의미 정리):

혈압 > 맥압 수정

검사 결과: 혈압, 콜레스테롤, 혈당 등

타겟 변수: 흡연 여부(label > 0=비흡연, 1=흡연)

데이터 크기, 결측치 비율 등 간단 요약.

## 2.2 기본 전처리(Basic Preprocessing)

결측치 처리(missing value imputation) 없음

이상치 처리(outlier handling) IQR기반으로 조건식 변환

train.loc[train['시력'] > 2, '시력'] = 2.0
train.loc[train['혈청 크레아티닌'] > 1.5, '혈청 크레아티닌'] = 1.5
train.loc[train['요 단백'] > 4, '요 단백'] = 4.0 등

이상치또한 이진분류 모델은 이상치에 강력함에따라 과하게 조절하지않음.

## 2.3 파생 변수(Feature Engineering, 파생변수)

예시:

나이 구간(age group) + BMI 구간을 조합한 나이별_BMI구간,지단백간의 비율

일반화:

train['저밀도지단백_고밀도지단백_낮음'] = train['저밀도지단백'] / train['고밀도지단백']
train['고밀도지단백_저밀도지단백_높음'] = train['고밀도지단백'] / train['저밀도지단백']
train['중성지방_고밀도지단백_2이하'] = train['중성 지방'] / train['고밀도지단백'] 등

건강 위험도를 더 잘 반영할 수 있는 조합 변수 

랜덤포레스트 이진분류 모델을 사용할 예정으로 선형관계는 고려하지않음.

# 3. 데이터 분할 및 데이터 누수 방지 전략

(Data Splitting & Data Leakage Prevention)

## 3.1 올바른 데이터 분할 전략

예시:

Train: 모델 학습 및 하이퍼파라미터(하이퍼파라미터, hyperparameter) 튜닝

Validation(검증셋): 모델 선택 및 임계값(threshold) 조정

Test(테스트셋): 오직 최종 성능 평가와 제출(prediction only) 에만 사용

테스트셋으로는 절대피처 선택(feature selection),모델 구조 결정,
하이퍼파라미터 튜닝, 임계값 조정 등을 하지 않는다.

간단한 예: 잘못된 경우: “Test AUC를 올릴 때까지 threshold를 계속 조정 → 그 순간 test는 더 이상 ‘미지의 데이터’가 아니므로 데이터 누수.”

올바른 경우: “Train/Valid에서 threshold를 확정한 뒤, test는 한 번만 예측.”

* 3.2 리더보드(Leaderboard)와 데이터 누수

Public 리더보드: test의 일부만 사용하는 공개 점수판

Private 리더보드: 대회 종료 후 공개되는 최종 점수판

문제점 정리: Public 점수에 맞춰 계속 모델과 threshold를 바꾸면, 사실상 Public subset에 과적합 → Private 점수 붕괴 위험.

* 3.3 올바른 데이터 사용예시

| 구분    | 사용 목적     | 허용되는 작업               | 사용 금지 작업         |
| ----- | --------- | --------------------- | ---------------- |
| Train | 모델 학습     | 피처 엔지니어링, 학습          | 없음               |
| Valid | 모델 선택/튜닝  | 하이퍼파라미터, threshold 조정 | 테스트 점수에 맞춘 조정    |
| Test  | 최종 평가(제출) | 한 번의 예측               | 모델/threshold 재조정 |



# 4. 모델링 및 실험 과정 기록(Experiments)

* 4.1 1일차 정리
| 실험      | 내용                                 | 결과/문제        | 인사이트                       |
| -------  | ----------------------------------  | ------------ | -------------------------- |
| 1        | 여러 모델 시험, 실수로 회귀(regression) 모델 사용 | 리더보드 점수 ~0.5 | 문제 유형(분류 vs 회귀) 이해의 중요성 인지 |
| 기타      | 기본 전처리 + 단순 학습                  | 성능 평이        | 베이스라인 설정 단계                |


# 4.2 2일차 정리
| 실험  | 전략                               | 결과/문제                          | 인사이트                                         |
| --- | -------------------------------- | ------------------------------ | -------------------------------------------- |
| 1 | 여러 분류 모델 시도, 정확도 급상승             | 과적합 의심(Train/Valid 갭 큼)        | Cross-validation 필요성 인지                      |
| 2 | 피처 삭제 후, 정확도 위주 모델링              | 데이터 불균형으로 흡연자 예측 실패(Recall 낮음) | 정확도만 보면 안 되고, 클래스 불균형(class imbalance) 고려 필수 |
| 3| 컬럼 유지, 하이퍼파라미터 튜닝 + threshold 조정 | 리더보드 점수는 상승, 흡연자/비흡연자 예측 불균형   | “목표(흡연자 탐지)보다 리더보드 점수에 집착하는 위험” 확인           |

# 4.3 3일차 정리
| 실험  | 전략                                | 결과/문제                          | 인사이트                                  |
| --- | --------------------------------- | ------------------------------ | ------------------------------------- |
| 1 | 파생변수 생성 + GridSearch              | LB 점수 0.741 (전처리 없이 한 모델보다 낮음) | 파생변수가 항상 성능 향상 X, 검증 기반 검토 필요         |
| 2 | 시드 고정, 예측파일/과적합 여부 확인, 절대값·정확도 비교 | 과적합 지속                         | 절대값(확률)·정확도만으로는 일반화 성능 판단 어렵다는 점 인지   |
| 3 | 위 과정 수정, 정확도 극대화 시도               | 과적합, Recall 크게 감소(리콜 박살)       | “정확도 ↑ vs 흡연자 탐지율 ↓” Trade-off 명확히 체감 |

# 4.3 4일차 정리

* 종합:

* 현재 리더보드 점수: 약 0.74 ~ 0.75

* 하지만 높은 점수 모델일수록 Recall(특히 흡연자 클래스)에 손해를 보며, 과적합 경향이 강함.

# 5. 평가 지표 및 임계값 조정(Evaluation Metrics & Threshold Tuning)
5.1 혼동행렬(Confusion Matrix, 혼동행렬) 관점

| 실제\예측  | 비흡연(0) | 흡연(1) |
| ------ | ------ | ----- |
| 비흡연(0) | TN     | FP    |
| 흡연(1)  | FN     | TP    |


일반화:

흡연자 = 양성(1)

우리가 중요한 것은

재현율(Recall) = TP / (TP + FN)

필요 시 F1-score, AUC 등도 참고하되 Recall 우선.

5.2 Threshold(임계값) 조정

예시:

기본 threshold 0.5 → Recall이 낮고, 흡연자를 많이 놓침

threshold를 0.3까지 낮추면 → Recall은 올라가나 FP 증가

일반화:

검증셋(또는 교차 검증 결과)에서 여러 threshold 후보에 대해

Recall, Precision, F1, Accuracy를 비교

“흡연자를 놓치지 않는 범위에서 허용 가능한 FP 수준”을 팀이 정의

5.3 과적합 여부에 따른 비교(개요)
구분	Train 성능	Valid 성능	특징
정상 모델	둘이 비슷	큰 갭 없음	일반화 가능성 높음
과적합 모델	Train 매우 높음	Valid 상대적으로 낮음	리더보드 점수 불안정, Private 점수 위험

(실제 보고서에서는 여기에 본인 실험 결과 테이블/그래프 삽입)

6. 3일차 기준 핵심 인사이트 및 개선 방향(Insights & Next Steps)
6.1 핵심 인사이트 요약

리더보드 점수 = 목적이 아님

Public 점수에 맞춘 과한 튜닝 → Private 점수 붕괴 가능성 큼.

정확도 중심 사고의 한계

데이터 불균형 속에서 Accuracy가 높아도 흡연자 Recall이 낮으면 의미 없음.

과도한 파생변수와 하이퍼파라미터 튜닝이 항상 이득은 아님

전처리 없이 단순 모델이 더 나은 경우를 직접 경험.

Threshold 조정은 반드시 검증셋 기준으로

Test/리더보드 기반 threshold 조정은 데이터 누수 + 과적합.

6.2 앞으로의 개선 방향 제안
개선 항목	내용	기대 효과
교차 검증(Cross-Validation, 교차검증) 도입	Stratified K-Fold 등으로 Train/Valid 분할 반복	점수의 분산 감소, 일반화 성능 추정 정확도 ↑
클래스 불균형 처리	class weight, over/under-sampling, focal loss 등 검토	흡연자 Recall 향상
모델 단순화	불필요한 파생변수/복잡한 모델 제거	과적합 감소, 해석 가능성 ↑
Threshold 최적화	검증기반 threshold 탐색 후 고정	목표 지표(Recall) 중심의 일관된 의사결정
7. 결론(Conclusion)

본 미니프로젝트는 “흡연 여부 분류”라는 의료적 의미가 있는 문제를 통해,

데이터 누수(data leakage) 위험,

리더보드 과적합,

클래스 불균형과 평가 지표 선택의 중요성
을 실제로 체감하고 교훈을 얻는 과정이었다.

현재 리더보드 기준 0.74 ~ 0.765 구간의 성능을 보였으나,

높은 점수 모델일수록 흡연자 Recall이 떨어지고 과적합이 심해지는 경향을 확인하였다.

최종적으로는

교차 검증 기반으로 안정적인 모델을 선정하고,

검증셋 기준으로 threshold를 확정한 뒤

Test 데이터에는 오직 한 번의 예측만 수행함으로써,
데이터 누수를 방지하면서도 목적(흡연자 탐지)에 맞는 모델을 완성하는 것이 남은 목표이다.