# 1. 프로젝트 개요(Introduction)
## 1.1 문제 정의(Problem Definition)

* “건강 데이터에서 개인의 흡연 여부(label)를 예측하는 이진 분류(binary classification) 문제를 다룬다.”


* 입력: 건강검진 결과 및 특성(나이, BMI, 혈압, 혈액검사 등)

* 출력: 흡연 여부(흡연자 / 비흡연자,label)

* 목표: 데이터 분석결과 이상치나 결측치 보단 컬럼간의 상호관계및 우선도,
* 단순 정확도(accuracy) 흡연자를 놓치지 않는 재현율(recall) 을 우선시

## 지나친 과적합 없이, 데이터 분포 변화에도 견고한 모델 개발이 목적



# 1.2 비즈니스/의료적 관점에서의 중요성


흡연자는 향후 심혈관계·호흡기계 질환 위험이 높으므로, 조기 모니터링이 중요하다.

일반화: 의료 리스크 관점에서 “흡연자 → 양성 클래스(positive class)”로 두고,

위양성(검사시 양성 오탐)보다 위음성(검사시 음성 오탐) 을 더 크게 보는 의사결정 구조를 설명.

# 2. 데이터 및 전처리(Data & Preprocessing)
## 2.1 데이터 구성(Data Description)

(컬럼 의미 정리):

혈압 > 맥압 수정

검사 결과: 혈압, 콜레스테롤, 혈당 등

타겟 변수: 흡연 여부(label > 0=비흡연, 1=흡연)

데이터 크기, 결측치 비율 등 간단 요약.

## 2.2 기본 전처리(Basic Preprocessing)

결측치 처리(missing value imputation) 없음

이상치 처리(outlier handling) IQR기반으로 조건식 변환

train.loc[train['시력'] > 2, '시력'] = 2.0
train.loc[train['혈청 크레아티닌'] > 1.5, '혈청 크레아티닌'] = 1.5
train.loc[train['요 단백'] > 4, '요 단백'] = 4.0 등

이상치또한 이진분류 모델은 이상치에 강력함에따라 과하게 조절하지않음.

## 2.3 파생 변수(Feature Engineering, 파생변수)

예시:

나이 구간(age group) + BMI 구간을 조합한 나이별_BMI구간,지단백간의 비율

일반화:

train['저밀도지단백_고밀도지단백_낮음'] = train['저밀도지단백'] / train['고밀도지단백']
train['고밀도지단백_저밀도지단백_높음'] = train['고밀도지단백'] / train['저밀도지단백']
train['중성지방_고밀도지단백_2이하'] = train['중성 지방'] / train['고밀도지단백'] 등

건강 위험도를 더 잘 반영할 수 있는 조합 변수 

랜덤포레스트 이진분류 모델을 사용할 예정으로 선형관계는 고려하지않음.

# 3. 데이터 분할 및 데이터 누수 방지 전략

(Data Splitting & Data Leakage Prevention)

## 3.1 올바른 데이터 분할 전략

예시:

Train: 모델 학습 및 하이퍼파라미터(하이퍼파라미터, hyperparameter) 튜닝

Validation(검증셋): 모델 선택 및 임계값(threshold) 조정

Test(테스트셋): 오직 최종 성능 평가와 제출(prediction only) 에만 사용

테스트셋으로는 절대피처 선택(feature selection),모델 구조 결정,
하이퍼파라미터 튜닝, 임계값 조정 등을 하지 않는다.

간단한 예: 잘못된 경우: “Test AUC를 올릴 때까지 threshold를 계속 조정 → 그 순간 test는 더 이상 ‘미지의 데이터’가 아니므로 데이터 누수.”

올바른 경우: “Train/Valid에서 threshold를 확정한 뒤, test는 한 번만 예측.”

* 3.2 리더보드(Leaderboard)와 데이터 누수

Public 리더보드: test의 일부만 사용하는 공개 점수판

Private 리더보드: 대회 종료 후 공개되는 최종 점수판

문제점 정리: Public 점수에 맞춰 계속 모델과 threshold를 바꾸면, 사실상 Public subset에 과적합 → Private 점수 붕괴 위험.

* 3.3 올바른 데이터 사용예시

| 구분    | 사용 목적     | 허용되는 작업               | 사용 금지 작업         |
| ----- | --------- | --------------------- | ---------------- |
| Train | 모델 학습     | 피처 엔지니어링, 학습          | 없음               |
| Valid | 모델 선택/튜닝  | 하이퍼파라미터, threshold 조정 | 테스트 점수에 맞춘 조정    |
| Test  | 최종 평가(제출) | 한 번의 예측               | 모델/threshold 재조정 |



# 4. 모델링 및 실험 과정 기록(Experiments)

* 4.1 1일차 정리
| 실험      | 내용                                 | 결과/문제        | 인사이트                       |
| -------  | ----------------------------------  | ------------ | -------------------------- |
| 1        | 여러 모델 시험, 실수로 회귀(regression) 모델 사용 | 리더보드 점수 ~0.5 | 문제 유형(분류 vs 회귀) 이해의 중요성 인지 |
| 기타      | 기본 전처리 + 단순 학습                  | 성능 평이        | 베이스라인 설정 단계                |
* 특이사항: 전처리 없는 모델이 리더보드상에 더 적합한 현상이 나타남.


# 4.2 2일차 정리
| 실험  | 전략                               | 결과/문제                          | 인사이트                                         |
| --- | -------------------------------- | ------------------------------ | -------------------------------------------- |
| 1 | 여러 분류 모델 시도, 정확도 급상승             | 과적합 의심(Train/Valid 갭 큼)        | Cross-validation 필요성 인지                      |
| 2 | 피처 삭제 후, 정확도 위주 모델링              | 데이터 불균형으로 흡연자 예측 실패(Recall 낮음) | 정확도만 보면 안 되고, 클래스 불균형(class imbalance) 고려 필수 |
| 3| 컬럼 유지, 하이퍼파라미터 튜닝 + threshold 조정 | 리더보드 점수는 상승, 흡연자/비흡연자 예측 불균형   | “목표(흡연자 탐지)보다 리더보드 점수에 집착하는 위험” 확인           |

# 4.3 3일차 정리
| 실험  | 전략                                | 결과/문제                          | 인사이트                                  |
| --- | --------------------------------- | ------------------------------ | ------------------------------------- |
| 1 | 파생변수 생성 + GridSearch              | LB 점수 0.741 (전처리 없이 한 모델보다 낮음) | 파생변수가 항상 성능 향상 X, 검증 기반 검토 필요         |
| 2 | 시드 고정, 예측파일/과적합 여부 확인, 절대값·정확도 비교 | 과적합 지속                         | 절대값(확률)·정확도만으로는 일반화 성능 판단 어렵다는 점 인지   |
| 3 | 위 과정 수정, 정확도 극대화 시도               | 과적합, Recall 크게 감소(리콜 박살)       | “정확도 ↑ vs 흡연자 탐지율 ↓” Trade-off 명확히 체감 |

# 4.4 4일차 정리

* 종합:

* 현재 리더보드 점수: 약 0.74 ~ 0.75

* 하지만 높은 점수 모델일수록 Recall(특히 흡연자 클래스)에 손해를 보며, 과적합 경향이 강함.
* 파생변수가 추가될 수록 모델의 정확도가 소폭 상승하는 경향이 있음.

# 4.5 5일차 정리
* 종합 :
* 앙상블 모델 2개 제출,스플릿없이 제출 결과: 앙상블 모델은 과적합경향이보임 0.76점이상에도 0.741~0.742 사이에 머무르는 경향이있음.
* 오히려 스플릿없이 제출된모델이 과적합이 덜 걸리는 현상이 있음.

# 4.6 6일차 정리
* 종합:
* 검증시 0.7635점수지만 리더보드에 적합하지 않은 경우가 있음. 고려사항:파생변수,모델파라미터 세부조정. 단순할수록 예측점수가 높다.
* 스플릿 없이 예측 시 0.764점이상이 나올 수 있음. 스플릿없이 모델링 >스플릿> 예측 허나 이는 모델링을 잘못하여 과적합된경우. 예측 점수가 무너지기 쉽다는것을 알게됨.
* 제출시 신중을 기여할 필요가 있음. 마지막 7일차 8일차 이후 보고서를 토대로 제출필요.

# 5. 평가 지표 및 임계값 조정(Evaluation Metrics & Threshold Tuning)
* 5.1 혼동행렬(Confusion Matrix, 혼동행렬) 관점

| 실제\예측  | 비흡연(0) | 흡연(1) |
| ------ | ------ | ----- |
| 비흡연(0) | TN     | FP    |
| 흡연(1)  | FN     | TP    |


일반화: 흡연자 = 양성(1)

우리가 중요한 것은 재현율(Recall) = TP / (TP + FN)

필요 시 F1-score, AUC 등도 참고하되 Recall 우선.

# 5.2 Threshold(임계값) 조정

예시: 기본 threshold 0.5 → Recall이 낮고, 흡연자를 많이 놓침

threshold를 0.3까지 낮추면 → Recall은 올라가나 FP(긍정을 틀림) 증가

일반화: 검증셋(또는 교차 검증 결과)에서 여러 threshold 후보에 대해

Recall, Precision, F1, Accuracy를 비교

“흡연자를 놓치지 않는 범위에서 허용 가능한 FP 수준” 을 팀이 정의 예상가능 양성 값:0.67~0.7

5.3 과적합 여부에 따른 비교(개요)
구분	Train 성능	Valid 성능	특징
정상 모델	둘이 비슷	큰 갭 없음	일반화 가능성 높음
과적합 모델	Train 매우 높음	Valid 상대적으로 낮음	리더보드 점수 불안정, Private 점수 위험

| 모델                         | 1차 Train Acc(훈련 정확도) | 1차 Valid Acc(검증 정확도) | 1차 Gap(Train-Valid) | 1차 CV Mean | 2차 Train Acc | 2차 Valid Acc | 2차 Gap(Train-Valid) | 2차 CV Mean |
| -------------------------- | -------------------- | -------------------- | ------------------- | ---------- | ------------ | ------------ | ------------------- | ---------- |
| RandomForestClassifier     | 1.0000               | 0.7450               | 0.2550              | 0.7313     | 1.0000       | 0.7350       | 0.2650              | 0.7390     |
| GradientBoostingClassifier | 0.7738               | 0.7364               | 0.0373              | 0.7283     | 0.7729       | 0.7236       | 0.0493              | 0.7241     |
| XGBClassifier              | 0.9864               | 0.7193               | 0.2671              | 0.7260     | 0.9825       | 0.7229       | 0.2596              | 0.7173     |
| SVC                        | 0.6993               | 0.7157               | -0.0164             | 0.7010     | 0.6950       | 0.7121       | -0.0171             | 0.6963     |
| LogisticRegression         | 0.7068               | 0.7150               | -0.0082             | 0.7064     | 0.7046       | 0.7236       | -0.0189             | 0.7070     |
| DecisionTreeClassifier     | 1.0000               | 0.6650               | 0.3350              | 0.6777     | 1.0000       | 0.6764       | 0.3236              | 0.6720     |

---
파생변수에 의한 비교 표
| 모델                           | 1차 Valid | 2차 Valid | 차이(1차−2차)   | 해석                 |
| ---------------------------- | -------- | -------- | ----------- | ------------------ |
| RandomForest (랜덤 포레스트)       | 0.7450   | 0.7350   | **+0.0100** | 파생변수가 약간 도움        |
| GradientBoosting (그래디언트 부스팅) | 0.7364   | 0.7236   | **+0.0129** | 파생변수 덕분에 ~1.3%p 상승 |
| XGB                          | 0.7193   | 0.7229   | **−0.0036** | 거의 비슷, 2차가 약간 우위   |
| SVC                          | 0.7157   | 0.7121   | **+0.0036** | 미세하게 1차가 낫지만 거의 동일 |
| LogisticRegression (로지스틱 회귀) | 0.7150   | 0.7236   | **−0.0086** | 원시데이터 쪽이 더 잘 맞음    |
| DecisionTree (단일 트리)         | 0.6650   | 0.6764   | **−0.0114** | 원시데이터 쪽이 조금 더 나음   |



# 6. 6일차 기준 핵심 인사이트 및 개선 방향(Insights & Next Steps)
* 6.1 핵심 인사이트 요약

리더보드 점수 = 목적이 아님

Public 점수에 맞춘 과한 튜닝 → Private 점수 붕괴 가능성 큼.

정확도 중심 사고의 한계

데이터 불균형 속에서 Accuracy가 높아도 흡연자 Recall이 낮으면 의미 없음.

과도한 파생변수와 하이퍼파라미터 튜닝이 항상 이득은 아님

전처리 없이 단순 모델이 더 나은 경우를 직접 경험.

Threshold 조정은 반드시 검증셋 기준으로

Test/리더보드 기반 threshold 조정은 데이터 누수 + 과적합.(주의 필요)

# 6.2 앞으로의 개선 방향 제안

| 개선 항목                            | 내용                                                 | 기대 효과                      |
| -------------------------------- | -------------------------------------------------- | -------------------------- |
| 교차 검증(Cross-Validation, 교차검증) 도입 | Stratified K-Fold 등으로 Train/Valid 분할 반복            | 점수의 분산 감소, 일반화 성능 추정 정확도 ↑ |
| 클래스 불균형 처리                       | class weight, over/under-sampling, focal loss 등 검토 | 흡연자 Recall 향상              |
| 모델 단순화                           | 불필요한 파생변수/복잡한 모델 제거                                | 과적합 감소, 해석 가능성 ↑           |
| Threshold 최적화                    | 검증기반 threshold 탐색 후 고정                             | 목표 지표(Recall) 중심의 일관된 의사결정 |

7. 결론(Conclusion)

본 미니프로젝트는 “흡연 여부 분류”라는 의료적 의미가 있는 문제를 통해,

데이터 누수(data leakage) 위험,리더보드 과적합,클래스 불균형과 평가 지표 선택의 중요성,
하이퍼 파라미터 미세조정,데이터의 한계,정확도 중심의 사고한계,다양한 인사이트 추출 등
머신러닝 대회에서 생각할 수 있는 모든 가능성을 시도해볼 수 있는 좋은 기회.

현재 리더보드 기준 0.74 ~ 0.765 구간의 성능을 보였으나,오히려 데이터셋이 작은경우,

과한 튜닝과 파생변수 추가 이상치 처리가 상호작용을 받아 과적합이 발생하는 경우가 확인되었다.

높은 점수 모델일수록 흡연자 Recall이 떨어지고 과적합이 심해지는 경향을 확인하였다.

## 최종적으로는

교차 검증 기반으로 "안정적인 모델을 선정"하고,

검증셋 기준으로 threshold를 확정한 뒤

Test 데이터에는 오직 한 번의 예측만 수행함으로써,

데이터 누수를 방지하면서도 목적(흡연자 탐지)에 맞는 모델을 완성하는 것이 남은 목표이다.
